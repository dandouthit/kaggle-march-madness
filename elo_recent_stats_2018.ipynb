{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "75e9ecc0-52e5-437f-baf1-90f44c091727",
    "_uuid": "9853586a0dc75ce39e7c7ffcde1eb4d47c6fb02e"
   },
   "source": [
    "## Overview ##\n",
    "\n",
    "This is a starter notebook inspired by last year's [Logistic Regression on Tournament Seeds by Kasper P. Lauritzen](https://www.kaggle.com/kplauritzen/notebookde27b18258?scriptVersionId=804590) starter kernel. It creates a basic logistic regression model based on the seed differences between teams. \n",
    "\n",
    "Note that the predictions for Stage 1's sample submissions file are already based on known outcomes, and the Tourney data this model is trained on includes that data. For Stage 2, you will be predicting future outcomes based on the teams selected for the tournament on March 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "0c233e05-c63d-4866-96dc-bb38d444bf84",
    "_uuid": "5464dc4b196dc4c8dd0323bbd71b75724113e2af",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "c0a759ab-6ffb-4b4a-8a1c-506ee7e6c452",
    "_uuid": "83c12faa8a2c0c0613d80896acf0615b13c5f05f",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "data_dir = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "09ccd5ae-5cd3-4888-824d-5d3f8b2a7ee9",
    "_uuid": "819472385a23f3fd5aaf4172b4f8db227cf5271f"
   },
   "source": [
    "## Load the training data ##\n",
    "I'm building off of the starter notebook by including DetailedResults for a \"past 10 game\" average, and season ending ELO ratings from Liam Kirwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "a68b8497-f64d-41a5-a271-fc12cc9ab7a5",
    "_uuid": "bf8ee168a0372e883332d6bb0ce5c89c13143650"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../data/rolling_average_data10.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8c5940933a1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_average_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'rolling_average_data10.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_seeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'NCAATourneySeeds.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_tour\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'NCAATourneyCompactResults.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_elo_ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'season_elos.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tfdeeplearning/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tfdeeplearning/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tfdeeplearning/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tfdeeplearning/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tfdeeplearning/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'../data/rolling_average_data10.csv' does not exist"
     ]
    }
   ],
   "source": [
    "df_average_data = pd.read_csv(data_dir + 'rolling_average_data10.csv')\n",
    "df_seeds = pd.read_csv(data_dir + 'NCAATourneySeeds.csv')\n",
    "df_tour = pd.read_csv(data_dir + 'NCAATourneyCompactResults.csv')\n",
    "df_elo_ratings = pd.read_csv(data_dir + 'season_elos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f4c0faa0-37e5-4492-938f-a09bc9c0e627",
    "_uuid": "7311741323866a33e130b5e485a961fcfaa9f1eb"
   },
   "outputs": [],
   "source": [
    "df_average_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "209f60c1-96de-49cb-a03e-5e3d5d6b38d5",
    "_uuid": "ce69d86cc6f2c2695045718c5008a0b20ae9408b"
   },
   "outputs": [],
   "source": [
    "df_elo_ratings = df_elo_ratings.rename(columns={'team_id':'WTeamID', 'season': 'Season'})\n",
    "df_elo_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1dba1495-530a-496f-afa6-50685c30dc4e",
    "_uuid": "42f99f53dd385e23b09378e0de9d3fce5eb1a2e9"
   },
   "source": [
    "First, we'll simplify the datasets to remove the columns we won't be using and convert the seedings to the needed format (stripping the regional abbreviation in front of the seed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "70c0899f-8c18-4d11-b679-0c51fe7dd206",
    "_uuid": "fcb18269a41cfa257bd97c40664e43e701251bed",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def seed_to_int(seed):\n",
    "    #Get just the digits from the seeding. Return as int\n",
    "    s_int = int(seed[1:3])\n",
    "    return s_int\n",
    "df_seeds['seed_int'] = df_seeds.Seed.apply(seed_to_int)\n",
    "df_seeds.drop(labels=['Seed'], inplace=True, axis=1) # This is the string label\n",
    "df_seeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dca6ca55-a9b4-482f-8a28-75262f3642da",
    "_uuid": "1f6ecb82fa587f5a95a6833cd224b01407f5c90a"
   },
   "outputs": [],
   "source": [
    "df_tour.drop(labels=['DayNum', 'WScore', 'LScore', 'WLoc', 'NumOT'], inplace=True, axis=1)\n",
    "df_tour.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "171b9e77-96af-4043-87aa-62513320a8df",
    "_uuid": "3f223cdf4446d6e9c77ab8319237f05393d1a822"
   },
   "source": [
    "## Merge seed for each team ##\n",
    "Merge the Seeds and ELO ratings with their corresponding TeamIDs in the compact results dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4d8d13db-d26a-47ff-b942-f7a8d6af6ac1",
    "_uuid": "53638c1ae27cfb24d47e02007c293d5ee19ebdac",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_winseeds = df_seeds.rename(columns={'TeamID':'WTeamID', 'seed_int':'WSeed'})\n",
    "df_lossseeds = df_seeds.rename(columns={'TeamID':'LTeamID', 'seed_int':'LSeed'})\n",
    "df_dummy = pd.merge(left=df_tour, right=df_winseeds, how='left', on=['Season', 'WTeamID'])\n",
    "df_concat = pd.merge(left=df_dummy, right=df_lossseeds, on=['Season', 'LTeamID'])\n",
    "df_concat['SeedDiff'] = df_concat.WSeed - df_concat.LSeed\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7945a7c6-c32e-44de-9dfe-4cf29cadad2a",
    "_uuid": "94855cfb715758bafaeb6cde81dbc8af01384c33",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_concat = pd.merge(left=df_concat, right=df_elo_ratings, how='left', on=['Season', 'WTeamID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "688559b4-8f4a-4309-ad44-16b1a0bb7a74",
    "_uuid": "78e2e390cfe9cd6ccd9142768bf86ab0922137b0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_concat = df_concat.rename(columns={'season_elo': 'WTeamELO'})\n",
    "df_elo_ratings = df_elo_ratings.rename(columns={'WTeamID': 'LTeamID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a5c88d3d-3a95-437c-b1c5-6e0d7a960ea9",
    "_uuid": "5df50347627449eb20f36d669c31e04532ae9d4f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_concat = pd.merge(left=df_concat, right=df_elo_ratings, how='left', on=['Season', 'LTeamID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a6224879-1894-44b8-a292-b30523c98b9e",
    "_uuid": "d2ac01d3d795aa73c30ce1904235eff8f66ecbad",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_concat = df_concat.rename(columns={'season_elo': 'LTeamELO'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fde74880-67e5-4287-b7e7-9da011491e29",
    "_uuid": "0493a59f84d3a3c28f65d1df24f73d2927cb0042"
   },
   "outputs": [],
   "source": [
    "df_concat.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.Season.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_average_data.Season.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d243d2f8-1e76-4ba9-9c98-694d6da9ac33",
    "_uuid": "09867847a5e95797394b48f3c2603d60e944b26d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Also drop the rows for which we don't have rolling averages\n",
    "df_concat = df_concat[df_concat['Season'] > 2009]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b6b0a655-6843-4521-9422-821f9540c9cb",
    "_uuid": "a62eac0f2dcc12b64484b5ce60342d9669c3665e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_concat.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1599a4aa-b01d-4e65-afd4-bf6b4eb516f6",
    "_uuid": "26530e0e83518a0a218c71ead248114ae4305538",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_average_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_average_data[df_average_data.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ccbcd0ab-92a9-41a0-935b-d64f72000c37",
    "_uuid": "5e17708462b2a85cca87be8a79411209f1a1785e",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# identify columns with NaN (dirty free throw data) and \"normalize\" to 70%\n",
    "#df_average_data[df_average_data.isnull().any(axis=1)]\n",
    "#values= {'FTPAvg': 70.0}\n",
    "#df_average_data = df_average_data.fillna(value=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_average_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_average_data = df_average_data.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5df3cc28-321a-450a-aa0c-f102c9e43d24",
    "_uuid": "ba5eece806146b6391ef2fd813a46b8f8f56c242",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_average_data[df_average_data.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_average_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8e203825-6a0b-4304-afff-63b175d43ee6",
    "_uuid": "1c82f60c02545c8c46ab090cb8cefca48e48e434"
   },
   "source": [
    "Now we'll create a vector that contains rolling average stats along with the ELO ratings for both winning and losing teams. \n",
    "Also want to randomize whether or not Team 1 or Team 2 is first in the X vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_average_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b2778056-90bd-40f2-8767-2ab8a9f9c052",
    "_uuid": "093436ea385768c4f5d07a75359a240f30e9c68d"
   },
   "outputs": [],
   "source": [
    "#X_train = np.zeros(shape=(n_test_games, 10))\n",
    "X_train = []\n",
    "y_train = []\n",
    "# find end of season ELO ratings and regular season rolling averages for each tournament game played\n",
    "for ii, row in df_concat.iterrows():\n",
    "    win_team_features = []\n",
    "    lose_team_features = []\n",
    "    win_elo = row.WTeamELO\n",
    "    lose_elo = row.LTeamELO\n",
    "    win_team_features.append(win_elo)\n",
    "    lose_team_features.append(lose_elo)\n",
    "    # don't want to append the season and team ID here\n",
    "    win_team_avgs = df_average_data[(df_average_data.Season == row.Season) & (df_average_data.TeamID == row.WTeamID)].iloc[0].values[2:]\n",
    "    for average in win_team_avgs:\n",
    "        win_team_features.append(average)\n",
    "        \n",
    "    lose_team_avgs = df_average_data[(df_average_data.Season == row.Season) & (df_average_data.TeamID == row.LTeamID)].iloc[0].values[2:]\n",
    "    for average in lose_team_avgs:\n",
    "        lose_team_features.append(average)\n",
    "    \n",
    "    # Randomly select win and lose order to train for both classes (0 and 1)\n",
    "    if random.random() > 0.5:\n",
    "        X_train.append(win_team_features + lose_team_features)\n",
    "        y_train.append(1)\n",
    "    else:\n",
    "        X_train.append(lose_team_features + win_team_features)\n",
    "        y_train.append(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c0faebd3-84e9-42b4-b3c2-b8eda141cd8c",
    "_uuid": "ca0c2ab70981888d3a0a1118075761d1f19a98a7",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "print(\"X_train length is: \" + str(len(X_train)))\n",
    "print(\"y_train length is: \" + str(len(y_train)))\n",
    "print(\"First item in X_train vector is:\")\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d4edf599-d55b-48a3-ba04-d4fd4d72387a",
    "_uuid": "911746ce4968843af037e8584bb5f0cc05e0e591",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6034ed92-f25d-4f39-b774-5ff88059527e",
    "_uuid": "64bda03dd002ed09c52b6f4c04fe249a34807379",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d09f56d5-25dd-4e3a-b692-e0d226bcd3b9",
    "_uuid": "563937f42bcccd2bbfb8fc1a66a72a9ca1351f43"
   },
   "source": [
    "## Train the model ##\n",
    "Use a basic logistic regression to train the model. You can set different C values to see how performance changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3a8ab699-fcd0-4313-bfe5-6d4111e1a9df",
    "_uuid": "95f817451eae9b72dc237e734e19c929be136d50",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "params = {'C': np.logspace(start=-5, stop=3, num=25)}\n",
    "clf = GridSearchCV(logreg, params, scoring='neg_log_loss', refit=True)\n",
    "clf.fit(X_train, y_train)\n",
    "print('Best log_loss: {:.4}, with best C: {}'.format(clf.best_score_, clf.best_params_['C']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f42898a1-93de-4a48-84e9-130ec67a6307",
    "_uuid": "13dd8086d0cfb72ace325485d9af148ca413c9b8"
   },
   "source": [
    "## Format season and team IDs from the SampleSubmissionStage1.csv file ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "07d4db38-119b-4937-8ed1-58efde9cf548",
    "_uuid": "cd5a427eca09adda4e9a42a88208b683020a1f8d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample_sub = pd.read_csv(data_dir + 'SampleSubmissionStage2.csv')\n",
    "n_test_games = len(df_sample_sub)\n",
    "\n",
    "def get_year_t1_t2(ID):\n",
    "    \"\"\"Return a tuple with ints `year`, `team1` and `team2`.\"\"\"\n",
    "    return (int(x) for x in ID.split('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample_sub.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0b17437d-3f01-465c-b796-5dc18eb06360",
    "_uuid": "6d5911dd84dcbab1a14943c6f6aec78b1580d708",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Confirm that the df_elo_ratings still has complete (1985-2018) data\n",
    "df_elo_ratings.Season.sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8ed172e5-9df2-44e5-b9d8-5d9e3691644b",
    "_uuid": "6bc18ac49c7e547d81150cf9b1343fb0223ce023",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rename team ID column back to the generic form\n",
    "df_elo_ratings = df_elo_ratings.rename(columns={'LTeamID': 'TeamID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "874207db-fc68-40bc-b7dc-a08548af11cb",
    "_uuid": "ecc747e9b4bc771dcb49d8499646f04ad117511b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_elo_ratings.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "57e2efd3-8c9e-444a-b4b1-74d053ba88e6",
    "_uuid": "1f06625879428776b0c429eb33623244cea6c804"
   },
   "source": [
    "## Changed function from sample notebook to grab ELO Ratings and averaged stats##\n",
    "Create predictions using the logistic regression model we trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2765c604-9a1f-43b0-8ad7-b2fd6aad9c6b",
    "_uuid": "72d64ebc20c903660108ae9c529be07859396909",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = []\n",
    "for ii, row in df_sample_sub.iterrows():\n",
    "    team1_features = []\n",
    "    team2_features = []\n",
    "    year, t1, t2 = get_year_t1_t2(row.ID)\n",
    "    t1_elo = df_elo_ratings[(df_elo_ratings.TeamID == t1) & (df_elo_ratings.Season == year)].season_elo.values[0]\n",
    "    t1_avgs = df_average_data[(df_average_data.Season == year) & (df_average_data.TeamID == t1)].iloc[0].values[2:]\n",
    "    t2_elo = df_elo_ratings[(df_elo_ratings.TeamID == t2) & (df_elo_ratings.Season == year)].season_elo.values[0]\n",
    "    t2_avgs = df_average_data[(df_average_data.Season == year) & (df_average_data.TeamID == t2)].iloc[0].values[2:]\n",
    "    team1_features.append(t1_elo)\n",
    "    for average in t1_avgs:\n",
    "        team1_features.append(average)\n",
    "    team2_features.append(t2_elo)\n",
    "    for average in t2_avgs:\n",
    "        team2_features.append(average)\n",
    "    X_test.append(team1_features + team2_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6533f8f5-7a6c-4d4b-b548-ba4e6cc9083c",
    "_uuid": "375748512c55520e00ffd5701c82704856478370"
   },
   "source": [
    "## Make Predictions ##\n",
    "Create predictions using the logistic regression model we trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "64b5f0d8-f35e-4f62-9be4-6c057920466a",
    "_uuid": "8321468d87c16f628ed24064c60f968efb3e8835",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a9667862-8b3e-4faa-8245-514ef509c79c",
    "_uuid": "65dc063a2e9c5e447d800556f7cf67b26b7cbedb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = clf.predict_proba(X_test)[:,1]\n",
    "df_sample_sub.Pred = preds\n",
    "df_sample_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7b4af526-02e9-4b72-b75d-60c6a3828c60",
    "_uuid": "3f4ef6ab893953a811462d240778205c2fdecf97"
   },
   "source": [
    "Lastly, create your submission file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a8fc4626-aa1b-4c78-92c8-94048561e3a5",
    "_uuid": "7c784a9b62d889e83493b70efa17bd233f9abff4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample_sub.to_csv('dan_douthit_elo_recent_stats_2018.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7ac2637b-cf5e-44fa-8af7-f8a3d626379c",
    "_uuid": "f33813ca63fd3fea0ce6d13565317fbe94e21789",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
